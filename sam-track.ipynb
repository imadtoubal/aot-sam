{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import glob\n",
    "from helpers import *\n",
    "from vot.region.io import read_trajectory\n",
    "from SegTracker import SegTracker\n",
    "from model_args import segtracker_args, sam_args, aot_args\n",
    "\n",
    "DATASET = '../vot-mixformer-sam/sequences'\n",
    "# SEQ = 'cat'\n",
    "SEQ = 'ants1'\n",
    "seq = os.path.join(DATASET, SEQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_paths = sorted(glob.glob(os.path.join(seq, 'color/*.jpg')))\n",
    "gt_paths =  sorted(glob.glob(os.path.join(seq, 'groundtruth_obj*.txt')))\n",
    "\n",
    "first_img = cv2.imread(imgs_paths[0])\n",
    "initial_mask = np.zeros(first_img.shape[:2], dtype=np.uint8)\n",
    "\n",
    "for i, gt_path in enumerate(gt_paths, 1):\n",
    "    curr_obj = read_trajectory(gt_path)[0]\n",
    "    bounds = curr_obj.bounds()\n",
    "    initial_mask[bounds[1]:bounds[3]+1, bounds[0]:bounds[2]+1] = curr_obj.mask * i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/mvl2/itdfh/anaconda3/envs/vot/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./ckpt/groundingdino_swint_ogc.pth \n",
      " => _IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight'])\n",
      "SegTracker has been initialized\n"
     ]
    }
   ],
   "source": [
    "seg_tracker = SegTracker(segtracker_args, sam_args, aot_args)\n",
    "seg_tracker.restart_tracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_args = {\n",
    "  'output_video': f'output_videos/{SEQ}.mp4',\n",
    "  'output_masked_frame_dir': 'masked_frames',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed frame 324, obj_num 6\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "# create dir to save predicted mask and masked frame\n",
    "output_mask_dir = 'output'\n",
    "os.makedirs(output_mask_dir, exist_ok=True)\n",
    "os.makedirs(io_args['output_masked_frame_dir'], exist_ok=True)\n",
    "\n",
    "pred_list = []\n",
    "masked_pred_list = []\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "sam_gap = seg_tracker.sam_gap\n",
    "frame_idx = 0\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    for img_path in imgs_paths:\n",
    "        frame_name = os.path.basename(img_path).split('.')[0]\n",
    "        frame = cv2.imread(img_path)\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if frame_idx == 0:\n",
    "            seg_tracker.add_reference(frame, initial_mask)\n",
    "            torch.cuda.empty_cache()\n",
    "            pred_mask = initial_mask\n",
    "            \n",
    "        # elif (frame_idx % sam_gap) == 0:\n",
    "        #     seg_mask = seg_tracker.seg(frame)\n",
    "        #     torch.cuda.empty_cache()\n",
    "            \n",
    "        #     track_mask = seg_tracker.track(frame)\n",
    "        #     # find new objects, and update tracker with new objects\n",
    "        #     new_obj_mask = seg_tracker.find_new_objs(track_mask,seg_mask)\n",
    "        #     save_prediction(new_obj_mask, output_mask_dir, f'{frame_name}_new.png')\n",
    "        #     pred_mask = track_mask + new_obj_mask\n",
    "        #     # Seg_Tracker.restart_tracker()\n",
    "        #     seg_tracker.add_reference(frame, pred_mask)\n",
    "        else:\n",
    "            pred_mask = seg_tracker.track(frame, update_memory=True)\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "        save_prediction(pred_mask, output_mask_dir, f'{frame_name}.png')\n",
    "        pred_list.append(pred_mask)\n",
    "\n",
    "        print(\"processed frame {}, obj_num {}\".format(frame_idx, seg_tracker.get_obj_num()),end='\\r')\n",
    "        frame_idx += 1\n",
    "    print('\\nfinished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 00000325 writed\n",
      "out.mp4 saved\n",
      "\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Visualization\n",
    "##################\n",
    "\n",
    "# draw pred mask on frame and save as a video\n",
    "height, width = pred_list[0].shape\n",
    "fourcc =  cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "\n",
    "fps=30\n",
    "out = cv2.VideoWriter(io_args['output_video'], fourcc, fps, (width, height))\n",
    "\n",
    "frame_idx = 0\n",
    "for img_path in imgs_paths:\n",
    "    frame_name = os.path.basename(img_path).split('.')[0]\n",
    "    frame = cv2.imread(img_path)\n",
    "    frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    pred_mask = pred_list[frame_idx]\n",
    "    masked_frame = draw_mask(frame, pred_mask)\n",
    "    masked_pred_list.append(masked_frame)\n",
    "    cv2.imwrite(f\"{io_args['output_masked_frame_dir']}/{frame_name}.png\", masked_frame[:, :, ::-1])\n",
    "\n",
    "    masked_frame = cv2.cvtColor(masked_frame,cv2.COLOR_RGB2BGR)\n",
    "    out.write(masked_frame)\n",
    "    print('frame {} writed'.format(frame_name),end='\\r')\n",
    "    frame_idx += 1\n",
    "out.release()\n",
    "print(\"\\n{} saved\".format(io_args['output_video']))\n",
    "print('\\nfinished')\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
